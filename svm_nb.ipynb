{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM**\n",
    "\n",
    " - *support vector* 만 찾아내면 결정경계가 정의되기 때문에 *다른 데이터샘플을 무시할 수있어서 속도가 빠름* \n",
    " - hyperplane - 2차원에서는 직선, 3차원에서는 면\n",
    "\n",
    " - hard margin - outlier를 허용하지 않음 과대적합가능성 (모든 데이터를 학습시킴)\n",
    " - soft margin  - outlier 어느정도 허용 - 어느정도 과소적합가능\n",
    " - regularization parameter  마진 최대화하면서 동시에 오분류 (outlier) 최소화 하기 위한 tradeoff 조정 \n",
    " - 최적화를 위해 여러개의 조합을 테스트 하기 때문에 상대적으로 학습속도를 느릴 수 있지만 딥러닝보다는 대체로 빠름 \n",
    " - **kernel svm** 비선형방식에서 svm 사용할때 \n",
    "     - `커널` 원데이터를 더 높은 차원으로 변환하는 알고리즘 \n",
    "     - 선형분리가 어려운 데이터에는 비선형접근인 `커널` 사용\n",
    " - **structural svm**\n",
    "    -  라벨 여러개 일때, 분류 모델\n",
    "\n",
    "\n",
    "\n",
    "**사용 방법**\n",
    "```python\n",
    "from sklearn.svm import SVC, SVR\n",
    "```\n",
    "```python\n",
    "model_svm = SVC(kernel='linear', random_state=123)\n",
    "model_svm.fit(X_train, Y_train)\n",
    "Y_trpred = model_svm.predict(X_train)\n",
    "Y_tepred = model_svm.predict(X_test)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
